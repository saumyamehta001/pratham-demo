{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(label, image):\n",
    "    pass\n",
    "    cv2.imshow(label, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def addPadding(im):\n",
    "    desired_size = 46\n",
    "    #im = cv2.imread(im_pth)\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # new_size should be in (width, height) format\n",
    "\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "    color = [255, 255, 255]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "        value=color)\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][0]))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts)\n",
    "\n",
    "def adjust_gamma(image, gamma=1.5):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as npThank\n",
    "\n",
    "def box_extraction(img_for_box_extraction_path):\n",
    "    img = cv2.imread(img_for_box_extraction_path)  # Read the image\n",
    "    img = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "    img = adjust_gamma(img,1.5)\n",
    "    showImage(\"gamma\", img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    showImage(\"gray\", gray)\n",
    "    img_bin= cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "  # Thresholding the image\n",
    "    showImage(\"img_bin\", img_bin)\n",
    "    \n",
    "    \n",
    "    img_bin = 255-img_bin  # Invert the image\n",
    "    cv2.imwrite(\"Image_bin.jpg\",img_bin)\n",
    "\n",
    "    # Defining a kernel length\n",
    "    #kernel_length = np.array(img).shape[1]//40\n",
    "    kernel_length = img.shape[1]//40\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # Morphological operation to detect verticle lines from an image\n",
    "    showImage(\"initial\"  , img_bin)\n",
    "    \n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    \n",
    "    showImage(\"eroded\"  , img_temp1)\n",
    "    \n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=5)\n",
    "    showImage(\"dilated\"  , verticle_lines_img)\n",
    "    \n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=5)\n",
    "    cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=1)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    showImage(\"image final bin\",img_final_bin)\n",
    "    cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # For Debugging\n",
    "    # Enable this line to see verticle and horizontal lines in the image which is used to find boxes\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(\n",
    "        img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    contours = sort_contours(contours)\n",
    "    roilist=[]\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        \n",
    "        #print(x , \" \", y, \" \", h, \" \", w)\n",
    "        if (h >20 and h<30 and w >29 and w<51) :\n",
    "            \n",
    "            new_img = img[y+1:y+h-1, x+1:x+w-1]\n",
    "            showImage(\"new\", new_img)\n",
    "            roilist.append(new_img)\n",
    "\n",
    "\n",
    "#     characters = ['0','1','2','3','4','5','6','7','8','9']\n",
    "#     #print(\"size\", len(roilist))\n",
    "#     responselist = \"\"\n",
    "    k=0\n",
    "    for roi in roilist:\n",
    "        thresh = 170    \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n",
    "        k+=1\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        showImage(\"first\", gray)\n",
    "        #im_bw = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,51,12)\n",
    "        _,im_bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        showImage(\"second\", im_bw)\n",
    "\n",
    "        im_bw = cv2.erode(im_bw, kernel, iterations=1)\n",
    "        showImage(\"erode\", im_bw)\n",
    "        _,im_bw = cv2.threshold(im_bw, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        #showImage(\"threshold\", im_bw)\n",
    "        #cv2.imwrite(\"im_bw.jpg\",im_bw)\n",
    "        height,width = im_bw.shape\n",
    "        im_bw = cv2.resize(im_bw,dsize = (width*5,height*4),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        showImage(\"resize\", im_bw)\n",
    "        ret,thresh = cv2.threshold(im_bw,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        im2,ctrs,hier = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        m = list()\n",
    "        sorted_ctrs = sorted(ctrs, key = lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        #print(\"sizes\", len(sorted_ctrs))\n",
    "        \n",
    "        pchl = list()\n",
    "\n",
    "        dp = im_bw.copy()\n",
    "\n",
    "        \n",
    "        for i,ctr in enumerate(sorted_ctrs):\n",
    "            if (i ==0):\n",
    "                x,y,w,h = cv2.boundingRect(ctr)\n",
    "\n",
    "                #print(\"Height, Weight, W/h, X , Y ->\",h,w,float(w)/h,x,y)\n",
    "\n",
    "\n",
    "                if float (w/h) < 3 and x>5 and y>10:\n",
    "                    roi = im_bw[y-10:y+h+10, x-5:x+w+10]\n",
    "                else:\n",
    "                    roi = im_bw \n",
    "                roi = addPadding(roi)\n",
    "                showImage(\";atts\", roi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_extraction('answers/2.1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
