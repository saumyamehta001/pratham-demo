{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import imutils\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from math import sqrt,atan2,hypot\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(name,image):\n",
    "    cv2.imshow(name,image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(l1,l2):\n",
    "    return np.min(distance.cdist(l1,l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata():\n",
    "    metadata={}\n",
    "    metadata[\"page_1\"] = [{\"x\":184 , \"y\":414 , \"h\":29 , \"w\":85, \"qno\":\"1.1\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":400 , \"y\":414 , \"h\":29 , \"w\":85, \"qno\":\"1.2\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":183 , \"y\":624 , \"h\":28 , \"w\":85, \"qno\":\"2.1\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":399 , \"y\":624 , \"h\":28 , \"w\":86, \"qno\":\"2.2\", \"type\":\"digit_rec\"}]\n",
    "    metadata[\"page_2\"]=  [{\"x\":213 , \"y\":336 , \"h\":29 , \"w\":86, \"qno\":\"3\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":212 , \"y\":625 , \"h\":28 , \"w\":86, \"qno\":\"4\", \"type\":\"digit_rec\"}]\n",
    "    metadata[\"page_3\"] = [{\"x\":236 , \"y\":219 , \"h\":29 , \"w\":85, \"qno\":\"5.1\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":235 , \"y\":332 , \"h\":30 , \"w\":86, \"qno\":\"5.2\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":233 , \"y\":502 , \"h\":30 , \"w\":86, \"qno\":\"6.1\", \"type\":\"digit_rec\"},\n",
    "                        {\"x\":232 , \"y\":624 , \"h\":29 , \"w\":86, \"qno\":\"6.2\", \"type\":\"digit_rec\"}]\n",
    "    metadata[\"page_4\"]=  [{\"x\":353 , \"y\":315 , \"h\":45 , \"w\":32, \"qno\":\"7\", \"type\":\"digit_rec_ver\"},\n",
    "                        {\"x\":353 , \"y\":450 ,\"h\": 45 , \"w\":32, \"qno\":\"8.1\", \"type\":\"digit_rec_ver\"},\n",
    "                        {\"x\":113 , \"y\":580 , \"h\":47 , \"w\":76, \"qno\":\"8.2\", \"type\":\"shaded_frac\",\"rows\":1,\"cols\":3,\"parts\":2,\"frac_type\":\"square\"}]\n",
    "    metadata[\"page_5\"] = [{\"x\":270 , \"y\":298 , \"h\":25 , \"w\":125, \"qno\":\"9\", \"type\":\"OMR\", \"xrange\":\"{'A':42, 'B': 72, 'C': 102, 'D': 132 }\"},\n",
    "                        {\"x\":180 , \"y\":408 , \"h\":210, \"w\":100, \"qno\":\"10.1\", \"type\":\"matching_pair\"}]\n",
    "    metadata[\"page_6\"] = [{\"x\":307 , \"y\":391 , \"h\":29 , \"w\":65, \"qno\":\"10.2 \", \"type\":\"digit_rec\"}]\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_digit_model():\n",
    "    json_file = open('model/digit_recognition.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights('model/digit_recognition.h5')\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omr_response(image, omr_range):\n",
    "    \n",
    "    omr_range = ast.literal_eval(omr_range)\n",
    "\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.minThreshold = 10;\n",
    "    params.maxThreshold = 200;\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 100\n",
    "    params.maxArea = 400\n",
    "    params.filterByCircularity = True\n",
    "    params.maxCircularity = 0.9\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = 0.87\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.01\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    keypoints = detector.detect(image)\n",
    "    #im_with_keypoints = cv2.drawKeypoints(image, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    detected_point = keypoints[0].pt\n",
    "    #print(detected_point)\n",
    "    if (len(keypoints)) == 0:\n",
    "        return \"\"\n",
    "    else :\n",
    "        for key,val in omr_range.items():\n",
    "            if(detected_point[0] < val):\n",
    "                return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(im):\n",
    "    desired_size = 46\n",
    "    #im = cv2.imread(im_pth)\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    \n",
    "    # new_size should be in (width, height) format\n",
    "    \n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    \n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    \n",
    "    color = [255, 255, 255]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "    value=color)\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(contours_hierarchy,imagecpy):\n",
    "    square_contours=[]\n",
    "    contours_hierarchy = list(contours_hierarchy)\n",
    "    for c in contours_hierarchy:\n",
    "        h = c[1]\n",
    "       \n",
    "        perimeter = cv2.arcLength(c[0], True)\n",
    "        approx = cv2.approxPolyDP(c[0], 0.02*perimeter, True)\n",
    "        if len(approx)!=4 or (len(approx)==4 and h[3]<0) :\n",
    "            square_contours.append(c)\n",
    "    return square_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.5):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_extraction(image,page_type,start_point,end_point):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_gray = cv2.fastNlMeansDenoising(gray,None,7,21)\n",
    "\n",
    "    _,thresh = cv2.threshold(denoised_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    _, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    imagecpy = image.copy()\n",
    "\n",
    "    cnt_hierarchy = zip(contours,hierarchy[0])\n",
    "    \n",
    "    cnt_hierarchy = sort_contours(cnt_hierarchy,imagecpy)\n",
    "    print(hierarchy[0])\n",
    "\n",
    "    l = []\n",
    "    roilist = []\n",
    "    letter_contours = []\n",
    "    for index,hierarchy in enumerate(cnt_hierarchy):\n",
    "        h = hierarchy[1]\n",
    "#(h[0] > -1 and h[1]) > -1 or (h[0]>-1 and h[2]>-1)\n",
    "        if (h[0]>-1 and h[3]<0):\n",
    "            letter_contours.append(contours[index])\n",
    "        elif h[0]==-1:\n",
    "            outer_contour = contours[index]\n",
    "            \n",
    "    if page_type== \"digit_rec\":\n",
    "        letter_contours = sorted(letter_contours,key = lambda lc:cv2.boundingRect(lc)[0])\n",
    "        position = [\"None\"]*len(letter_contours)\n",
    "        contour_positions = []\n",
    "        for index,lc in enumerate(letter_contours):\n",
    "            contour_positions.append({\"contour\":lc,\"position\":position[index]})\n",
    "        \n",
    "    elif page_type == \"digit_rec_ver\":\n",
    "        contour_positions = []\n",
    "\n",
    "        letter_contours = sorted(letter_contours,key = lambda lc:cv2.boundingRect(lc)[1])\n",
    "        if len(letter_contours)==1:\n",
    "            letter_contours = np.vstack(letter_contours).squeeze()\n",
    "            xo,yo,wo,ho = cv2.boundingRect(outer_contour)\n",
    "            xi,yi,wi,hi = cv2.boundingRect(letter_contours)\n",
    "            \n",
    "            num_dsit =abs(yi-yo)\n",
    "            \n",
    "            deno_dist = abs(yi-(yo+ho))\n",
    "            print(\"num {}, den {}\".format(num_dsit,deno_dist))\n",
    "            position = \"numerator\" if num_dsit<deno_dist else  \"denominator\"\n",
    "            contour_positions = [{\"contour\":letter_contours,\"position\":position}]\n",
    "        else:\n",
    "            position = [None]*len(letter_contours)\n",
    "            position[0] = \"numerator\"\n",
    "            position[1] = \"denominator\"\n",
    "            for lc in letter_contours:\n",
    "                contour_positions.append({\"contour\":lc,\"position\":position})\n",
    "       \n",
    "        \n",
    "    for item in contour_positions:\n",
    "        x,y,w,h = cv2.boundingRect(item[\"contour\"])\n",
    "        show_image(\"imagecpy_box\",thresh[y-1:y+h+1,x-1:x+w+1])\n",
    "        roilist.append({\"image\":thresh[y-1:y+h+1,x-1:x+w+1],\"position\":item[\"position\"]})\n",
    "    \n",
    "    return roilist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shaded_regions(circle_fraction,center,radius,parts,angle):\n",
    "    # need to know how many parts are asked \n",
    "    hist_sums = []\n",
    "    images_list=[]\n",
    "    additon_angle = 360/parts\n",
    "    for i in range(int(angle),-360,-int(additon_angle)):\n",
    "        deg1=i\n",
    "        deg2 = deg1-additon_angle\n",
    "        color=(255,255,255)\n",
    "        axes= (radius,radius)\n",
    "\n",
    "        mask = np.zeros(circle_fraction.shape,np.uint8)\n",
    "        circle_mask = np.zeros(circle_fraction.shape,np.uint8)\n",
    "        cv2.ellipse(circle_mask,center, axes,0, deg1, deg2, color,-1,8,0);\n",
    "\n",
    "        mask_res = cv2.bitwise_and(circle_fraction,circle_mask)\n",
    "\n",
    "\n",
    "        mask_res[np.where(mask_res==0)]=255\n",
    "\n",
    "\n",
    "        new_image_gray = cv2.cvtColor(mask_res,cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit= 3.0, tileGridSize =(8,8))\n",
    "        roi_hist_eq = clahe.apply(new_image_gray)\n",
    "\n",
    "        ret,new_image_thresh = cv2.threshold(roi_hist_eq,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "        images_list.append(new_image_thresh)\n",
    "        hist_row = np.count_nonzero(255 - new_image_thresh,axis=0)\n",
    "        hist_col = np.count_nonzero(255 - new_image_thresh,axis=1)\n",
    "        hist_sums.append(np.sum(hist_row)+np.sum(hist_col))\n",
    "    shaded_indices = [x for x in hist_sums if x>1500 and x>np.max(hist_sums)*0.8]\n",
    "    return str(len(shaded_indices))+\"/\"+str(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circle_frac(circle_fraction,parts,init_angle):\n",
    "    circle_frac_gray = cv2.cvtColor(circle_fraction,cv2.COLOR_BGR2GRAY)\n",
    "    circle_frac_denoised_gray = cv2.fastNlMeansDenoising(circle_frac_gray, None, 7, 21)\n",
    "    ret,circle_frac_thresh = cv2.threshold(circle_frac_denoised_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    canny = cv2.Canny(circle_frac_gray,0,50)\n",
    "    circles=[]\n",
    "    (_,contours,_) = cv2.findContours(canny,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    contours = sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "    for contour in contours:\n",
    "        if(len(contour)>4):\n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            (x,y),(MA,ma),angle  = cv2.fitEllipse(contour)\n",
    "                #add it\n",
    "            a = ma/2\n",
    "            b = MA/2\n",
    "\n",
    "            circle_fractioncpy = circle_fraction.copy()\n",
    "\n",
    "            eccentricity = sqrt(pow(a,2)-pow(b,2))\n",
    "            eccentricity = round(eccentricity/a,2)\n",
    "\n",
    "\n",
    "\n",
    "            if(eccentricity <= 0.5):\n",
    "                circles.append(contour)\n",
    "\n",
    "\n",
    "    circle_fractioncpy = circle_fraction.copy()\n",
    "\n",
    "    circle_outer = sorted(circles,key=cv2.contourArea,reverse=True)[0]\n",
    "\n",
    "\n",
    "    # # cropping using circle\n",
    "\n",
    "    (x,y),radius = cv2.minEnclosingCircle(circle_outer)\n",
    "    center = (int(x),int(y))\n",
    "    radius = int(radius)\n",
    "    x = int((x - radius))\n",
    "    y = int((y - radius))\n",
    "    return get_shaded_regions(circle_fraction,center,radius,parts,init_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_frac(square_fraction,num_rows,num_cols):\n",
    "    square_fraction_gray = cv2.cvtColor(square_fraction,cv2.COLOR_BGR2GRAY)\n",
    "    square_fraction_denoised_gray = cv2.fastNlMeansDenoising(square_fraction_gray, None, 7, 21)\n",
    "    ret,thresh_square = cv2.threshold(square_fraction_denoised_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_TRIANGLE)\n",
    "\n",
    "    hist_sums = []\n",
    "    height,width = thresh_square.shape\n",
    "\n",
    "    desired_height = int(height/num_rows)\n",
    "\n",
    "    desired_width = int(width/num_cols)\n",
    "\n",
    "    for x in range(0,width-desired_width+1,desired_width):\n",
    "        for y in range(0,height-desired_height+1,desired_height):\n",
    "            if x>0:\n",
    "                rect = thresh_square[y:y+desired_height-1,x-1:x+desired_width-1]\n",
    "            else:\n",
    "                rect = thresh_square[y:y+desired_height-1,x:x+desired_width-1]\n",
    "\n",
    "            hist_row = np.count_nonzero(255-rect,axis=0)\n",
    "            hist_col = np.count_nonzero(255-rect,axis=1)\n",
    "            hist_sums.append(sum(hist_row)+sum(hist_col))\n",
    "    shaded_indices = [x for x in hist_sums if x>500 and x>=np.max(hist_sums)*0.5]\n",
    "    return str(len(shaded_indices))+\"/\"+str(num_rows*num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_pairs(image):\n",
    "    image = cv2.fastNlMeansDenoisingColored(image,None,10,10,7,21)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image_copy=image.copy()\n",
    "    thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                    cv2.THRESH_BINARY_INV,11,2)\n",
    "    lines = cv2.HoughLinesP(thresh,1,np.pi/180,threshold=30,minLineLength=30,maxLineGap=30)\n",
    "    t1=[]\n",
    "    init_points = []\n",
    "    final_points = []\n",
    "    points=[]\n",
    "    \n",
    "    if not np.any(lines):\n",
    "        return(\"No matches\")\n",
    "    else:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            points.append([ x1,y1,x2,y2])\n",
    "    points = sorted(points,key=lambda x:x[1])\n",
    "    print(points)\n",
    "    init_y,end_y=points[0][1],points[0][1]\n",
    "\n",
    "    duplicate_points=[]\n",
    "    for i in range(0,len(points)-1):\n",
    "        for j in range(i+1,len(points)):\n",
    "            if points[j][1] in range(points[i][1],points[i][1]+30):\n",
    "                 points[j][1] = points[i][1]\n",
    "    print(\"points\",points)\n",
    "    duplicate_distances = [{\"x1\":x1,\"y1\":y1,\"x2\":x2,\"y2\":y2,\"distance\":sqrt((y2-y2)**2+(x2-x1)**2)} for x1,y1,x2,y2 in points]\n",
    "    print(\"duplicate_distances\",duplicate_distances)\n",
    "    unique_y1={item['y1'] for item in duplicate_distances}\n",
    "    final_points = []\n",
    "    for y1 in unique_y1:\n",
    "        items = [item for item in duplicate_distances if item[\"y1\"]==y1]\n",
    "        index = np.argmax([item[\"distance\"] for item in items])\n",
    "        init_points.append(items[index][\"y1\"])\n",
    "        final_points.append(items[index][\"y2\"])\n",
    "    temp_order=[i[0] for i in sorted(enumerate(init_points),key=lambda x:x[1])]\n",
    "    init_points_sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "    init_points = list(zip(init_points,init_points_sorted_indices))\n",
    "    print(init_points)\n",
    "\n",
    "    temp_order=[i[0] for i in sorted(enumerate(final_points),key=lambda x:x[1])]\n",
    "    final_points_sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "    final_points = list(zip(final_points,final_points_sorted_indices))\n",
    "    print(final_points)\n",
    "    match_string = \"\"\n",
    "    for index in range(len(final_points)):\n",
    "        print(init_points[index][1],\"->\",final_points[index][1])\n",
    "        match_string+=str(init_points[index][1])+\"->\"+str(final_points[index][1])\n",
    "        if index< (len(final_points)-1):\n",
    "            match_string+=\",\"\n",
    "    return match_string\n",
    "#     for i,item in enumerate(points):\n",
    "#         x1,y1,x2,y2 = item[0],item[1],item[2],item[3]\n",
    "#         if i==0:\n",
    "#             duplicate_points.append([x1,y1,x2,y2])\n",
    "#             init_y=y1\n",
    "#         if i>1 and y1 in range(init_y,init_y+30):\n",
    "#             print(\"x1,y1,x2,y2\",x1,init_y,x2,y2)\n",
    "# #             cv2.line(image_copy,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "# #             show_image(\"image_copy\",image_copy)\n",
    "#             duplicate_points.append([x1,init_y,x2,y2])\n",
    "#             init_y=y1\n",
    "\n",
    "    \n",
    "#     temp_order=[i[0] for i in sorted(enumerate(init_points),key=lambda x:x[1][1])]\n",
    "#     init_points_sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "#     init_points = list(zip(init_points,init_points_sorted_indices))\n",
    "#     print(init_points)\n",
    "\n",
    "#     temp_order=[i[0] for i in sorted(enumerate(final_points),key=lambda x:x[1][1])]\n",
    "#     final_points_sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "#     final_points = list(zip(final_points,final_points_sorted_indices))\n",
    "#     print(final_points)\n",
    "\n",
    "#     for index in range(len(init_points)):\n",
    "#         print(init_points[index][1],\"->\",final_points[index][1])\n",
    "#             if(x2<=x1):\n",
    "#                     temp1=x1\n",
    "#                     temp2=y1\n",
    "#                     x1=x2\n",
    "#                     y1=y2\n",
    "#                     x2=temp1\n",
    "#                     y2=temp2\n",
    "#             slope=np.round((y2-y1)/(x2-x1),2)\n",
    "#             intercept=np.round(y1-slope*x1,2)\n",
    "#             angle=atan2(y2-y1,x2-x1)*180/np.pi\n",
    "#             print(\"angle\",angle)\n",
    "#             final_angle=(int)(angle/45)\n",
    "#             if( angle>=0):\n",
    "#                 if(angle-final_angle*45<10):\n",
    "#                     final_angle=final_angle*45\n",
    "#                 else:\n",
    "#                     final_angle=(final_angle+1)*45\n",
    "#             else:\n",
    "#                 if(angle-final_angle*45>-10):\n",
    "#                     final_angle=final_angle*45\n",
    "#                 else:\n",
    "#                     final_angle=(final_angle-1)*45\n",
    "#             angle=final_angle\n",
    "#             flag=1\n",
    "#             if(x1<=5):   \n",
    "#                 t1.append([x1,y1,x2,y2,slope,intercept,angle])\n",
    "#                 for i in range(0,len(t1)-1):\n",
    "#                     if(abs(t1[i][4]-t1[len(t1)-1][4])<=0.5 and abs(t1[i][5]-t1[len(t1)-1][5])<=5):\n",
    "#                         t1.pop(len(t1)-1)\n",
    "#                         flag=0\n",
    "#                         break\n",
    "\n",
    "#         t1 = sorted(t1, key=lambda x:x[1], reverse=False)\n",
    "#         match_string = \"\"\n",
    "#         b=0\n",
    "#         for i in range(len(t1)):\n",
    "#             a=i+1\n",
    "#             if(t1[i][1]==-1):\n",
    "#                 b=0\n",
    "#             else:\n",
    "#                 if(t1[i][6]==0-i*45):\n",
    "#                     b=1\n",
    "#                 elif(t1[i][6]==45-i*45):\n",
    "#                     b=2\n",
    "#                 elif(t1[i][6]==90-i*45):\n",
    "#                     b=3\n",
    "\n",
    "#             match_string += str(a)+\"->\"+str(b)\n",
    "#             if i< (len(t1)-1):\n",
    "#                 match_string+=\",\"\n",
    "#         return match_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify(h):\n",
    "    h = h.reshape((4,2))\n",
    "    hnew = np.zeros((4,2),dtype = np.float32)\n",
    "\n",
    "    add = h.sum(1)\n",
    "    hnew[0] = h[np.argmin(add)]\n",
    "    hnew[2] = h[np.argmax(add)]\n",
    "\n",
    "    diff = np.diff(h,axis = 1) \n",
    "    hnew[1] = h[np.argmin(diff)]\n",
    "    hnew[3] = h[np.argmax(diff)]\n",
    "\n",
    "    return hnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, target):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    approx = rectify(target)\n",
    "    (tl, tr, br, bl) = approx\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    pts1 = np.array([\n",
    "    [0, 0],\n",
    "    [maxWidth - 1, 0],\n",
    "    [maxWidth - 1, maxHeight - 1],\n",
    "    [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(approx,pts1)\n",
    "\n",
    "    warped = cv2.warpPerspective(image,M,(maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outerblobs(image):\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Change thresholds\n",
    "    params.minThreshold = 10;\n",
    "    params.maxThreshold = 200;\n",
    "\n",
    "    # Filter by Area.\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 200\n",
    "    params.maxArea = 400\n",
    "\n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.maxCircularity = 0.9\n",
    "\n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = 0.87\n",
    "\n",
    "    # Filter by Inertia\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.01\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    keypoints = detector.detect(image)\n",
    "    objects = []\n",
    "    for k in keypoints:\n",
    "        #print(k.pt)\n",
    "        objects.append((int(k.pt[0]), int(k.pt[1])))\n",
    "\n",
    "    points = np.array(objects)\n",
    "    #print(points)\n",
    "\n",
    "    max_x = max([_[0] for _ in points])\n",
    "    min_x = min([_[0] for _ in points])\n",
    "\n",
    "    max_y = max([_[1] for _ in points])\n",
    "    min_y = min([_[1] for _ in points])\n",
    "\n",
    "    points = [[min_x, min_y],\n",
    "                [max_x, min_y],\n",
    "                 [max_x, max_y],\n",
    "                 [min_x, max_y]\n",
    "             ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warped_image(image):\n",
    "    RESCALED_HEIGHT = 800.0\n",
    "    ratio = image.shape[0] / RESCALED_HEIGHT\n",
    "    rescaled_image = imutils.resize(image, height=int(RESCALED_HEIGHT))\n",
    "    points = detect_outerblobs(rescaled_image)\n",
    "    warped,M = four_point_transform(rescaled_image, np.array(points))\n",
    "    return warped,M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: {'A': 42, 'B': 72, 'C': 102, 'D': 132}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-3579d72a1652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mqtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"OMR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mxrange\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xrange\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_omr_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2a01e1212486>\u001b[0m in \u001b[0;36mget_omr_response\u001b[0;34m(image, omr_range)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_omr_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momr_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0momr_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momr_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleBlobDetector_Params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: {'A': 42, 'B': 72, 'C': 102, 'D': 132}"
     ]
    }
   ],
   "source": [
    "# image = cv2.imread(\"answers/7.png\")\n",
    "# box_extraction(image)\n",
    "filename = \"sheets/pratham-5.png\"\n",
    "page = filename.split(\"-\")[1].split(\".\")[0]\n",
    "image = cv2.imread(filename)\n",
    "warped,M = get_warped_image(image)\n",
    "show_image(\"warped\",warped)\n",
    "metadata = generate_metadata()\n",
    "metadata_page = metadata[\"page_\"+str(page)]\n",
    "margin = 3\n",
    "characters = ['0','1','2','3','4','5','6','7','8','9']\n",
    "model = load_digit_model()\n",
    "for metadata in metadata_page:\n",
    "    x,y,w,h = metadata[\"x\"],metadata[\"y\"],metadata[\"w\"],metadata[\"h\"]\n",
    "    qno = metadata[\"qno\"]\n",
    "    qtype = metadata[\"type\"]\n",
    "    rotated_point = M.dot(np.array((x,y) + (1,)))\n",
    "    rotated_point = rotated_point.astype(int)\n",
    "    cropped = warped[rotated_point[1]-margin:(rotated_point[1]+h)+margin, \n",
    "                     rotated_point[0]-margin:(rotated_point[0]+w)+margin]\n",
    "\n",
    "    if \"digit_rec\" in qtype:\n",
    "        new_point = rotated_point[:2]\n",
    "        init_new_point = np.array(new_point).reshape(1,-1)\n",
    "        end_new_point =  np.array([new_point[0]+w,new_point[1]+h]).reshape(1,-1)\n",
    "        box_info = box_extraction(cropped,qtype,init_new_point,end_new_point)\n",
    "        for info in box_info:\n",
    "            roi = cv2.resize(info[\"image\"],dsize = (28,28), interpolation = cv2.INTER_AREA)\n",
    "            show_image(\"roi\",roi)\n",
    "\n",
    "            roi = np.array(roi)\n",
    "            t = np.copy(roi)\n",
    "            t = t /255.0\n",
    "            t = 1 - t\n",
    "            t = np.transpose(t)\n",
    "            t = t.reshape(1,784)\n",
    "            pred = model.predict_classes(t)\n",
    "            print(pred)\n",
    "    elif qtype == \"shaded_frac\":\n",
    "        if metadata[\"frac_type\"] == \"square\":\n",
    "            shaded = get_square_frac(cropped,metadata[\"rows\"],metadata[\"cols\"])\n",
    "            print(shaded)\n",
    "    elif qtype == \"matching_pair\":\n",
    "        margin_init=15\n",
    "        margin_end=10\n",
    "        cropped = warped[rotated_point[1]+margin_init:(rotated_point[1]+h)-margin_init, \n",
    "                     rotated_point[0]+margin_end:(rotated_point[0]+w)-margin_end]\n",
    "        show_image(\"cropped\",cropped)\n",
    "\n",
    "        matches = get_matching_pairs(cropped)\n",
    "        print(matches)\n",
    "    elif qtype == \"OMR\":\n",
    "        xrange =metadata[\"xrange\"]\n",
    "        ans = get_omr_response(cropped,xrange)\n",
    "        print(ans)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "box_extraction() missing 3 required positional arguments: 'page_type', 'start_point', and 'end_point'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8fd137939b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"answers/1.1.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbox_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: box_extraction() missing 3 required positional arguments: 'page_type', 'start_point', and 'end_point'"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"answers/1.1.png\")\n",
    "box_extraction(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 1, 2]\n",
      "[([1, 1], 0), ([2, 200], 2), ([5, 500], 3), ([12, 179], 1)]\n",
      "[1, 2, 3, 0]\n",
      "[([1, 1800], 3), ([2, 0], 0), ([5, 50], 1), ([12, 179], 2)]\n"
     ]
    }
   ],
   "source": [
    "mylist = [[1,1],[2,200],[5,500],[12, 179]]\n",
    "mylist2 = [[1,1800],[2,0],[5,50],[12, 179]]\n",
    "temp_order=[i[0] for i in sorted(enumerate(mylist),key=lambda x:x[1][1])]\n",
    "print(temp_order)\n",
    "sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "print(list(zip(mylist,sorted_indices)))\n",
    "\n",
    "temp_order=[i[0] for i in sorted(enumerate(mylist2),key=lambda x:x[1][1])]\n",
    "print(temp_order)\n",
    "sorted_indices=sorted(range(len(temp_order)),key=lambda x:temp_order[x])\n",
    "print(list(zip(mylist2,sorted_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
